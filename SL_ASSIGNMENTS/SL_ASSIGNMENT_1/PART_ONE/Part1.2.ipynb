{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ff4220e",
   "metadata": {},
   "source": [
    "### 1.2 Filtered Boston housing and kernels\n",
    "\n",
    "Downloaded csv in command line using:\n",
    "`curl -o boston-filter.csv http://www0.cs.ucl.ac.uk/staff/M.Herbster/boston-filter/Boston-filtered.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60212353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import python_functions as py_func\n",
    "\n",
    "# dataset_np_headers_dropped\n",
    "ds = np.genfromtxt('boston-filter.csv', delimiter=',', skip_header=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Naive Regression\n",
    "a. Using polynomial basis for k=1 only i.e. $y = b$.\n",
    "\n",
    "b. The constant function effectively determines the bias ($y$-intercept) of the linear regression.\n",
    "It is the lowest predicted value of the dependent variable, the median house price."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "MSEs_train_part_a, MSEs_test_part_a = py_func.split_dataset_and_compute_20_MSEs_with_ones(ds)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "c. For each of the 12 attributes, perform a linear regression using only the single attribute but incorporating a bias term so that the inputs are augmented with an additional 1 entry, (xi , 1), so that we learn a weight vector w\n",
    " âˆˆ R2."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(Does this mean they want all 12 weights or the average of the 12 weights or MSEs .. ?)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means for each of the 12 attributes in train ds= \n",
      "[70.7041647837489, 72.03692002816041, 64.05057020382704, 80.34603836491502, 68.1197348390914, 43.675830130679536, 71.36935623649204, 78.04456954554622, 71.55957656203262, 65.32423821973977, 62.090915760503876, 37.47723015145918]\n",
      "\n",
      "Means for each of the 12 attributes in test ds= \n",
      "[74.4874685503509, 76.79322964603105, 66.16293396472426, 85.56934661294534, 71.1069732261131, 43.808498207167375, 74.93678917645552, 81.79524781858404, 73.52533896219495, 67.23687830792827, 64.18149020991304, 40.87963802805747]\n"
     ]
    }
   ],
   "source": [
    "MSEs_train_part_c, MSEs_test_part_c = py_func.split_dataset_and_compute_20_MSEs_with_single_attr(ds)\n",
    "\n",
    "means_train, means_test = [], []\n",
    "for MSEs_train_part_c_per_attr, MSEs_test_part_c_per_attr in zip(MSEs_train_part_c, MSEs_test_part_c):\n",
    "    means_train.append(np.mean(MSEs_train_part_c_per_attr))\n",
    "    means_test.append(np.mean(MSEs_test_part_c_per_attr))\n",
    "\n",
    "print(f'Means for each of the 12 attributes in train ds = \\n{means_train}\\n')\n",
    "print(f'Means for each of the 12 attributes in test ds = \\n{means_test}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "d. Perform linear regression using all of the data attributes at once.\n",
    "Perform linear regression on the training set using this regressor, and incorporate a bias term as above.\n",
    "\n",
    "Calculate the MSE on the training and test sets and note down the results.\n",
    "You should find that this method outperforms any of the individual regressors."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "MSEs_train_part_d, MSEs_test_part_d = py_func.split_dataset_and_compute_20_MSEs_with_all_12_attr(ds)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE for train dataset, using all 12 attributes = 21.70373755394515\n",
      "Mean MSE for test dataset, using all 12 attributes = 25.273765249937956\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean MSE for train dataset, using all 12 attributes = {np.mean(MSEs_train_part_d)}')  # gives 65.39992873551633\n",
    "print(f'Mean MSE for test dataset, using all 12 attributes = {np.mean(MSEs_test_part_d)}')  # gives 68.3736527258721"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.3 Kernelised ridge regression\n",
    "\n",
    "A Kernel function is given as an element-wise product ?:\n",
    "$K_{i,j} = K(x_i, x_j)$\n",
    "$l$ is the size of the training set.\n",
    "$\\gamma$ is the regularisation parameter.\n",
    "$\\sigma$ is a parameter of the Gaussian kernel.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "def gaussian_kernel(X, sigma: float):\n",
    "    num_of_rows_of_x = X.shape[0]\n",
    "    kernel_values = np.empty((num_of_rows_of_x, num_of_rows_of_x))\n",
    "    for i in range(num_of_rows_of_x):\n",
    "        for j in range(num_of_rows_of_x):\n",
    "            pairwise_difference = X[i] - X[j]\n",
    "            sqrd_norm = np.square(np.linalg.norm(pairwise_difference))\n",
    "            kernel_values[i][j] = np.exp(-1 * sqrd_norm / 2 * np.square(sigma))\n",
    "    return kernel_values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "g_dataset_30x, g_dataset_30y = py_func.generate_dataset_about_g(num_of_data_pairs=30)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 30)\n"
     ]
    }
   ],
   "source": [
    "# Create a vector of gamma values [2^-40, 2^-39,...,2^-26]\n",
    "gammas = [2**pow for pow in list(range(-40, -25))]\n",
    "# Create vector of sigma values [2^7, 2^7.5, . . . , 2^12.5, 2^13]\n",
    "sigmas = []\n",
    "for pow in list(range(7, 14)):\n",
    "    sigmas.append(2**pow)\n",
    "    sigmas.append(2**(pow+0.5))\n",
    "sigmas = sigmas[:-1]\n",
    "\n",
    "res = []\n",
    "for sigma in sigmas:\n",
    "\n",
    "    res.append(gaussian_kernel(g_dataset_30x, sigma))\n",
    "res = np.array(res)\n",
    "print(res.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "(30, 30)"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = gaussian_kernel(g_dataset_30x, sigmas[0])\n",
    "res.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "def a_star(sigma, dataset_x, gamma, dataset_y):\n",
    "    kernel_matrix = gaussian_kernel(dataset_x, sigma)\n",
    "    l = dataset_x.shape[0]\n",
    "    return (np.linalg.inv(kernel_matrix + gamma * l * np.identity(l))) @ dataset_y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "-0.38638126724692334"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "astar = a_star(sigma=128, dataset_x=g_dataset_30x, gamma=2**-40, dataset_y=g_dataset_30y)\n",
    "astar[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluation_of_regression(alpha_star, X_train, X_test_data_point):\n",
    "    y_test = []\n",
    "    for i in range(X_train.shape[0]):\n",
    "        bla = alpha_star[i]\n",
    "        print(bla.shape)\n",
    "\n",
    "    return 0\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13)\n",
      "(102, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "ds = np.genfromtxt('boston-filter.csv', delimiter=',', skip_header=1)\n",
    "train_dataset, test_dataset = train_test_split(ds, test_size=1 / 5)\n",
    "def get_x_train_y_train_x_test_y_test(m_train: int, train_ds, m_test: int, test_ds) -> tuple:\n",
    "    X_train_all_attr = train_ds[:, 0: 12]\n",
    "    ones_train = np.ones((m_train, 1))\n",
    "    X_train = np.column_stack((ones_train, X_train_all_attr))\n",
    "    y_train = train_ds[:, -1]\n",
    "    X_test_all_attr = test_ds[:, 0: 12]\n",
    "    ones_test = np.ones((m_test, 1))\n",
    "    X_test = np.column_stack((ones_test, X_test_all_attr))\n",
    "    y_test = test_ds[:, -1]\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "m_train, m_test = train_dataset.shape[0], test_dataset.shape[0]\n",
    "X_train, y_train, X_test, y_test = get_x_train_y_train_x_test_y_test(m_train=m_train, train_ds=train_dataset,\n",
    "                                                                     m_test=m_test, test_ds=test_dataset)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gaussian_kernel_of_test_point(X_test, X_test_point, sigma):\n",
    "    num_of_rows_of_x = X_test.shape[0]\n",
    "    sqrd_norm = np.empty(num_of_rows_of_x)\n",
    "    for i in range(num_of_rows_of_x):\n",
    "        pairwise_difference = X_test[i] - X_test_point\n",
    "        sqrd_norm[i] = np.square(np.linalg.norm(pairwise_difference))\n",
    "    return np.exp(-1 * sqrd_norm / 2 * sigma ** 2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1., 1.])"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "bla = np.ones(2)\n",
    "bla"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "2.0"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(bla, axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "[[2. 2.]\n",
      " [3. 2.]]\n",
      "[[1.5 2. ]\n",
      " [3.  3. ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.zeros((2,2))\n",
    "a[0,0] = 1\n",
    "a[0,1] = 2\n",
    "a[1,0] = 3\n",
    "a[1,1] = 4\n",
    "b = np.zeros((2,2))\n",
    "b[0,0] = 2\n",
    "b[0,1] = 2\n",
    "b[1,0] = 3\n",
    "b[1,1] = 2\n",
    "print(a)\n",
    "print(b)\n",
    "c = (a + b) / 2\n",
    "print(c)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_of_5folds=[[9702836.85669036, 13996061.59304154, 19224107.1127768524659123.90175939,\n",
    "  29047858.03471764, 31935351.63541982, 33607369.14736999, 34509284.16610817\n",
    "  34977977.00755431, 35216925.42095353, 35337571.86303162, 35398190.90625889\n",
    "  35428574.73176835]\n",
    " [ 9702836.85189835, 13996061.58613707, 19224107.10330123, 24659123.88961204\n",
    "  29047858.02041359, 31935351.61969705, 33607369.13082578, 34509284.14912088\n",
    "  34977976.99033677, 35216925.40361861, 35337571.84563743, 35398190.88883494\n",
    "  35428574.71432947]\n",
    " [ 9702836.84231433, 13996061.57232812, 19224107.08434998, 24659123.86531735\n",
    "  29047857.99180546, 31935351.5882515,  33607369.09773736, 34509284.11514632\n",
    "  34977976.9559017,  35216925.36894879, 35337571.81084908, 35398190.85398702\n",
    "  35428574.67945171]\n",
    " [ 9702836.82314628 13996061.54471024 19224107.0464475  24659123.81672797\n",
    "  29047857.93458923 31935351.52536041 33607369.03156052 34509284.04719717\n",
    "  34977976.88703158 35216925.29960914 35337571.74127236 35398190.78429119\n",
    "  35428574.60969618]\n",
    " [ 9702836.78481019 13996061.48947447 19224106.97064253 24659123.71954921\n",
    "  29047857.82015678 31935351.39957821 33607368.89920683 34509283.91129888\n",
    "  34977976.74929134 35216925.16092983 35337571.60211892 35398190.64489953\n",
    "  35428574.47018512]\n",
    " [ 9702836.70813801 13996061.37900294 19224106.81903259 24659123.52519169\n",
    "  29047857.59129186 31935351.14801385 33607368.63449948 34509283.63950231\n",
    "  34977976.47381084 35216924.88357124 35337571.32381207 35398190.36611621\n",
    "  35428574.19116299]\n",
    " [ 9702836.55479365 13996061.15805987 19224106.51581271 24659123.13647664\n",
    "  29047857.13356202 31935350.64488509 33607368.10508474 34509283.09590916\n",
    "  34977975.92284986 35216924.32885404 35337570.76719835 35398189.80854958\n",
    "  35428573.63311874]\n",
    " [ 9702836.24810495 13996060.71617376 19224105.90937298 24659122.35904659\n",
    "  29047856.2181024  31935349.63862765 33607367.04625536 34509282.00872292\n",
    "  34977974.82092796 35216923.2194197  35337569.65397096 35398188.69341637\n",
    "  35428572.51703028]\n",
    " [ 9702835.63472758 13996059.8324016  19224104.6964936  24659120.80418658\n",
    "  29047854.38718329 31935347.62611289 33607364.92859671 34509279.83435059\n",
    "  34977972.61708428 35216921.00055116 35337567.42751633 35398186.46315011\n",
    "  35428570.28485353]\n",
    " [ 9702834.40797302 13996058.06485752 19224102.2707352  24659117.694467\n",
    "  29047850.72534556 31935343.60108394 33607360.69328001 34509275.48560654\n",
    "  34977968.20939755 35216916.56281471 35337562.97460769 35398182.00261821\n",
    "  35428565.82050066]\n",
    " [ 9702831.95446459 13996054.52977038 19224097.41921975 24659111.47502962\n",
    "  29047843.40167218 31935335.55102832 33607352.22264902 34509266.78812094\n",
    "  34977959.39402659 35216907.68734434 35337554.06879296 35398173.08155695\n",
    "  35428556.89179744]\n",
    " [ 9702827.04745052 13996047.45960009 19224087.71619435 24659099.03616189\n",
    "  29047828.75433372 31935319.45092618 33607335.28139661 34509249.39315952\n",
    "  34977941.76329467 35216889.93641363 35337536.25717357 35398155.23944449\n",
    "  35428539.0344011 ]\n",
    " [ 9702817.23343348 13996033.31927552 19224068.31016551 24659074.15845459\n",
    "  29047799.45968995 31935287.25075836 33607301.39893014 34509214.60327606\n",
    "  34977906.50187068 35216854.43459237 35337500.63397507 35398119.55525994\n",
    "  35428503.31964883]\n",
    " [ 9702797.60544388 13996005.03869042 19224029.49819569 24659024.40315258\n",
    "  29047740.87053498 31935222.85056842 33607233.63415052 34509145.02366658\n",
    "  34977835.97918228 35216783.43111052 35337429.38773929 35398048.18705235\n",
    "  35428431.89030591]\n",
    " [ 9702758.3496425  13995948.47777635 19223951.87460747 24658924.89299898\n",
    "  29047623.69275536 31935094.05077142 33607098.10520457 34509005.86507733\n",
    "  34977694.93444374 35216641.4247894  35337286.89591251 35397905.45128305\n",
    "  35428289.03226652]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def find_gamma_sigma_pair_with_lowest_MSE_using_gaussian_KRR(ds):\n",
    "    _5_X_train, _5_y_train, _5_X_valid, _5_y_valid = generate_5_folds_from_dataset(ds)\n",
    "    gammas, sigmas = generate_gammas_and_sigmas()\n",
    "    mean_of_sqrd_errors_per_gs_pair_for_one_x_val = np.zeros((len(gammas), len(sigmas)))\n",
    "    MSEs_for_each_gs_pair_for_all_5folds = []\n",
    "\n",
    "    for X_train, y_train, X_val, y_val in zip(_5_X_train, _5_y_train, _5_X_valid, _5_y_valid):\n",
    "        for g, gamma in enumerate(gammas):\n",
    "            for s, sigma in enumerate(sigmas):\n",
    "                a_stars_for_this_gs_pair_and_fold = solve_dual_optimisation(X_train=X_train, gamma=gamma,\n",
    "                                                                            sigma=sigma, y_train=y_train)\n",
    "                sqrd_errors = []\n",
    "                for i, (x_val_row, y_val_row) in enumerate(zip(X_val, y_val)):\n",
    "                    y_test_pred = evaluation_of_regression(a_stars=a_stars_for_this_gs_pair_and_fold,\n",
    "                                                           X_train=X_train, X_val_row=x_val_row, sigma=sigma)\n",
    "\n",
    "                    sqrd_errors.append(np.square(y_test_pred - y_val_row))\n",
    "\n",
    "                assert len(sqrd_errors) == len(y_val), 'sqrd_errors list is not the expected length'\n",
    "                mean_of_sqrd_errors_per_gs_pair_for_one_x_val[g][s] = np.mean(sqrd_errors)\n",
    "\n",
    "        # HERE IS WHERE I HAVE SOME CONCERN THAT I SHOULD BE MAKING A COPY OR DEEPCOPY OF THE ARRAY, AS I MAY JUST END UP WITH 5 IDENTICAL VALUES IN THE 5 FOLDS\n",
    "        MSEs_for_each_gs_pair_for_all_5folds.append(mean_of_sqrd_errors_per_gs_pair_for_one_x_val)\n",
    "        mean_of_sqrd_errors_per_gs_pair_for_one_x_val = np.zeros((len(gammas), len(sigmas)))\n",
    "\n",
    "    fold1 = MSEs_for_each_gs_pair_for_all_5folds[0]\n",
    "    fold2 = MSEs_for_each_gs_pair_for_all_5folds[1]\n",
    "    fold3 = MSEs_for_each_gs_pair_for_all_5folds[2]\n",
    "    fold4 = MSEs_for_each_gs_pair_for_all_5folds[3]\n",
    "    fold5 = MSEs_for_each_gs_pair_for_all_5folds[4]\n",
    "\n",
    "    assert len(MSEs_for_each_gs_pair_for_all_5folds) == 5\n",
    "    mean_of_5folds = (fold1 + fold2 + fold3 + fold4 + fold5) / 5\n",
    "    index_of_lowest_mse = np.argmin(mean_of_5folds)\n",
    "    g_of_gs_pair_of_lowest_mse, s_of_gs_pair_of_lowest_mse = np.unravel_index(index_of_lowest_mse, mean_of_5folds.shape)\n",
    "    return mean_of_5folds, g_of_gs_pair_of_lowest_mse, gammas[g_of_gs_pair_of_lowest_mse], \\\n",
    "        s_of_gs_pair_of_lowest_mse, sigmas[s_of_gs_pair_of_lowest_mse]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.094947017729282e-13, 1.8189894035458565e-12, 3.637978807091713e-12, 7.275957614183426e-12, 1.4551915228366852e-11, 2.9103830456733704e-11, 5.820766091346741e-11, 1.1641532182693481e-10, 2.3283064365386963e-10, 4.656612873077393e-10, 9.313225746154785e-10, 1.862645149230957e-09, 3.725290298461914e-09, 7.450580596923828e-09, 1.4901161193847656e-08]\n",
      "15\n",
      "[128, 181.01933598375618, 256, 362.03867196751236, 512, 724.0773439350247, 1024, 1448.1546878700494, 2048, 2896.309375740099, 4096, 5792.618751480198, 8192]\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "def generate_gammas_and_sigmas() -> tuple:\n",
    "    gammas = [2 ** pow for pow in list(range(-40, -25))]\n",
    "    sigmas = []\n",
    "    for pow in list(range(7, 14)):\n",
    "        sigmas.append(2 ** pow)\n",
    "        sigmas.append(2 ** (pow + 0.5))\n",
    "    sigmas = sigmas[:-1]\n",
    "    return gammas, sigmas\n",
    "\n",
    "gammas, sigmas = generate_gammas_and_sigmas()\n",
    "print(gammas)\n",
    "print(len(gammas))\n",
    "print(sigmas)\n",
    "print(len(sigmas))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "data": {
      "text/plain": "9.094947017729282e-13"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**-40"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "1.4901161193847656e-08"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**-26"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SL_ASS1_kernel",
   "language": "python",
   "name": "sl_ass1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
