{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ff4220e",
   "metadata": {},
   "source": [
    "### 1.2 Filtered Boston housing and kernels\n",
    "\n",
    "Downloaded csv in command line using:\n",
    "`curl -o boston-filter.csv http://www0.cs.ucl.ac.uk/staff/M.Herbster/boston-filter/Boston-filtered.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60212353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import python_functions as py_func\n",
    "\n",
    "# dataset_np_headers_dropped\n",
    "ds = np.genfromtxt('boston-filter.csv', delimiter=',', skip_header=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Naive Regression\n",
    "a. Using polynomial basis for k=1 only i.e. $y = b$.\n",
    "\n",
    "b. The constant function effectively determines the bias ($y$-intercept) of the linear regression.\n",
    "It is the lowest predicted value of the dependent variable, the median house price."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "MSEs_train_part_a, MSEs_test_part_a = py_func.split_dataset_and_compute_20_MSEs_with_ones(ds)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "c. For each of the 12 attributes, perform a linear regression using only the single attribute but incorporating a bias term so that the inputs are augmented with an additional 1 entry, (xi , 1), so that we learn a weight vector w\n",
    " âˆˆ R2."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(Does this mean they want all 12 weights or the average of the 12 weights or MSEs .. ?)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means for each of the 12 attributes in train ds= \n",
      "[70.7041647837489, 72.03692002816041, 64.05057020382704, 80.34603836491502, 68.1197348390914, 43.675830130679536, 71.36935623649204, 78.04456954554622, 71.55957656203262, 65.32423821973977, 62.090915760503876, 37.47723015145918]\n",
      "\n",
      "Means for each of the 12 attributes in test ds= \n",
      "[74.4874685503509, 76.79322964603105, 66.16293396472426, 85.56934661294534, 71.1069732261131, 43.808498207167375, 74.93678917645552, 81.79524781858404, 73.52533896219495, 67.23687830792827, 64.18149020991304, 40.87963802805747]\n"
     ]
    }
   ],
   "source": [
    "MSEs_train_part_c, MSEs_test_part_c = py_func.split_dataset_and_compute_20_MSEs_with_single_attr(ds)\n",
    "\n",
    "means_train, means_test = [], []\n",
    "for MSEs_train_part_c_per_attr, MSEs_test_part_c_per_attr in zip(MSEs_train_part_c, MSEs_test_part_c):\n",
    "    means_train.append(np.mean(MSEs_train_part_c_per_attr))\n",
    "    means_test.append(np.mean(MSEs_test_part_c_per_attr))\n",
    "\n",
    "print(f'Means for each of the 12 attributes in train ds = \\n{means_train}\\n')\n",
    "print(f'Means for each of the 12 attributes in test ds = \\n{means_test}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "d. Perform linear regression using all of the data attributes at once.\n",
    "Perform linear regression on the training set using this regressor, and incorporate a bias term as above.\n",
    "\n",
    "Calculate the MSE on the training and test sets and note down the results.\n",
    "You should find that this method outperforms any of the individual regressors."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "MSEs_train_part_d, MSEs_test_part_d = py_func.split_dataset_and_compute_20_MSEs_with_all_12_attr(ds)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE for train dataset, using all 12 attributes = 21.70373755394515\n",
      "Mean MSE for test dataset, using all 12 attributes = 25.273765249937956\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean MSE for train dataset, using all 12 attributes = {np.mean(MSEs_train_part_d)}')  # gives 65.39992873551633\n",
    "print(f'Mean MSE for test dataset, using all 12 attributes = {np.mean(MSEs_test_part_d)}')  # gives 68.3736527258721"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.3 Kernelised ridge regression\n",
    "\n",
    "A Kernel function is given as an element-wise product ?:\n",
    "$K_{i,j} = K(x_i, x_j)$\n",
    "$l$ is the size of the training set.\n",
    "$\\gamma$ is the regularisation parameter.\n",
    "$\\sigma$ is a parameter of the Gaussian kernel.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "def gaussian_kernel(X, sigma: float):\n",
    "    num_of_rows_of_x = X.shape[0]\n",
    "    kernel_values = np.empty((num_of_rows_of_x, num_of_rows_of_x))\n",
    "    for i in range(num_of_rows_of_x):\n",
    "        for j in range(num_of_rows_of_x):\n",
    "            pairwise_difference = X[i] - X[j]\n",
    "            sqrd_norm = np.square(np.linalg.norm(pairwise_difference))\n",
    "            kernel_values[i][j] = np.exp(-1 * sqrd_norm / 2 * np.square(sigma))\n",
    "    return kernel_values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "g_dataset_30x, g_dataset_30y = py_func.generate_dataset_about_g(num_of_data_pairs=30)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 30)\n"
     ]
    }
   ],
   "source": [
    "# Create a vector of gamma values [2^-40, 2^-39,...,2^-26]\n",
    "gammas = [2**pow for pow in list(range(-40, -25))]\n",
    "# Create vector of sigma values [2^7, 2^7.5, . . . , 2^12.5, 2^13]\n",
    "sigmas = []\n",
    "for pow in list(range(7, 14)):\n",
    "    sigmas.append(2**pow)\n",
    "    sigmas.append(2**(pow+0.5))\n",
    "sigmas = sigmas[:-1]\n",
    "\n",
    "res = []\n",
    "for sigma in sigmas:\n",
    "\n",
    "    res.append(gaussian_kernel(g_dataset_30x, sigma))\n",
    "res = np.array(res)\n",
    "print(res.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "(30, 30)"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = gaussian_kernel(g_dataset_30x, sigmas[0])\n",
    "res.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "def a_star(sigma, dataset_x, gamma, dataset_y):\n",
    "    kernel_matrix = gaussian_kernel(dataset_x, sigma)\n",
    "    l = dataset_x.shape[0]\n",
    "    return (np.linalg.inv(kernel_matrix + gamma * l * np.identity(l))) @ dataset_y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "-0.38638126724692334"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "astar = a_star(sigma=128, dataset_x=g_dataset_30x, gamma=2**-40, dataset_y=g_dataset_30y)\n",
    "astar[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluation_of_regression(alpha_star, X_train, X_test_data_point):\n",
    "    y_test = []\n",
    "    for i in range(X_train.shape[0]):\n",
    "        bla = alpha_star[i]\n",
    "        rint(bla.shape)\n",
    "\n",
    "    return 0\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13)\n",
      "(102, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "ds = np.genfromtxt('boston-filter.csv', delimiter=',', skip_header=1)\n",
    "train_dataset, test_dataset = train_test_split(ds, test_size=1 / 5)\n",
    "def get_x_train_y_train_x_test_y_test(m_train: int, train_ds, m_test: int, test_ds) -> tuple:\n",
    "    X_train_all_attr = train_ds[:, 0: 12]\n",
    "    ones_train = np.ones((m_train, 1))\n",
    "    X_train = np.column_stack((ones_train, X_train_all_attr))\n",
    "    y_train = train_ds[:, -1]\n",
    "    X_test_all_attr = test_ds[:, 0: 12]\n",
    "    ones_test = np.ones((m_test, 1))\n",
    "    X_test = np.column_stack((ones_test, X_test_all_attr))\n",
    "    y_test = test_ds[:, -1]\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "m_train, m_test = train_dataset.shape[0], test_dataset.shape[0]\n",
    "X_train, y_train, X_test, y_test = get_x_train_y_train_x_test_y_test(m_train=m_train, train_ds=train_dataset,\n",
    "                                                                     m_test=m_test, test_ds=test_dataset)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gaussian_kernel_of_test_point(X_test, X_test_point, sigma):\n",
    "    num_of_rows_of_x = X_test.shape[0]\n",
    "    sqrd_norm = np.empty(num_of_rows_of_x)\n",
    "    for i in range(num_of_rows_of_x):\n",
    "        pairwise_difference = X_test[i] - X_test_point\n",
    "        sqrd_norm[i] = np.square(np.linalg.norm(pairwise_difference))\n",
    "    return np.exp(-1 * sqrd_norm / 2 * sigma ** 2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1., 1.])"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "bla = np.ones(2)\n",
    "bla"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "2.0"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(bla, axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SL_ASS1_kernel",
   "language": "python",
   "name": "sl_ass1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
